- size_t和ssize_t的区别

  - size_t是为了方便系统之间的移植而定义的，不同的系统上，定义可能不一样。size_t在32位系统上定义为typedef  unsigned int size_t;（4个字节） 而在64位架构中被定义为typedef  unsigned long size_t;（8个字节）  但int类型始终是4个字节。
  - ssize_t是有符号整型，在32位机器上等同int，64位机器上等同long int. ssize_t这个数据类型用来表示可以被执行读写操作的数据块的大小。
  - 为什么有时候不用int，而是用size_type或者size_t? 因为size_t的取值range是目标平台下最大可能的数组尺寸，使用int有可能浪费或者范围不够大。

  ```cpp
  //C语言中size_t的陷阱
  
  #include 
  #include 
  int main()
  {
      int i = -1;
      if(i > strlen("Demon"))
          printf("Hello World");
      else
          printf("Hello Demon");
      return 0;
  }
  //输出的是Hello World！-1 > 5？！
  //问题出在strlen上，strlen返回的类型是size_t，size_t的定义为：typedef unsigned int size_t; 即无符号的整型，而i的类型是int，即有符号的整型。当有符号整型和无符号整型进行运算时，有符号整型会先自动转化成无符号。-1转化成无符号数为4294967295，远远大于5。
  ```

- 字符编码
  - ASCII
  每一个二进制位（bit）有`0`和`1`两种状态，八个二进制位这被称为一个字节（byte）。一个字节一共可以用来表示256种不同的状态，每一个状态对应一个符号，就是256个符号，从`00000000`到`11111111`。上个世纪60年代，美国制定了一套字符编码，ASCII 码一共规定了128个字符的编码，对英语字符与二进制位之间的关系，做了统一规定。

  - 非ASCII编码
  英语用128个符号编码就够了，但是用来表示其他语言，128个符号是不够的。于是利用字节中闲置的最高位编入新的符号。比如，法语中的`é`的编码为130（二进制`10000010`）。这样一来，这些欧洲国家使用的编码体系，可以表示最多256个符号。
  但是，这里又出现了新的问题。不同的国家有不同的字母，因此，哪怕它们都使用256个符号的编码方式，代表的字母却不一样。比如，130在法语编码中代表了`é`，在希伯来语编码中却代表了字母`Gimel` (`ג`)，在俄语编码中又会代表另一个符号。但是不管怎样，所有这些编码方式中，0--127表示的符号是一样的，不一样的只是128--255的这一段。至于亚洲国家的文字使用的符号更多，汉字就多达10万左右。一个字节只能表示256种符号，肯定是不够的，就必须使用多个字节表达一个符号。比如，简体中文常见的编码方式是 GB2312，使用两个字节表示一个汉字，所以理论上最多可以表示 256 x 256 = 65536 个符号。
  中文编码的问题需要专文讨论，这篇笔记不涉及。这里只指出，虽然都是用多个字节表示一个符号，但是GB类的汉字编码与后文的 Unicode 和 UTF-8 是毫无关系的。

  - Unicode 是一种所有符号的编码，但它只是一个符号集，只规定了符号的二进制代码，却没有规定这个二进制代码应该如何存储。

  - UTF-8 是一种变长的编码方式。它可以使用1~4个字节表示一个符号，根据不同的符号而变化字节长度。UTF-8 的编码规则很简单，只有二条：
  1）对于单字节的符号，字节的第一位设为`0`，后面7位为这个符号的 Unicode 码。因此对于英语字母，UTF-8 编码和 ASCII 码是相同的。
  2）对于`n`字节的符号（`n > 1`），第一个字节的前`n`位都设为`1`，第`n + 1`位设为`0`，后面字节的前两位一律设为`10`。剩下的没有提及的二进制位，全部为这个符号的 Unicode 码。

  下表总结了编码规则，字母`x`表示可用编码的位。

  > ```
  > Unicode符号范围        |        UTF-8编码方式
  > (十六进制)             |              （二进制）
  > ----------------------+---------------------------------------------
  > 0000 0000-0000 007F   | 0xxxxxxx
  > 0000 0080-0000 07FF   | 110xxxxx 10xxxxxx
  > 0000 0800-0000 FFFF   | 1110xxxx 10xxxxxx 10xxxxxx
  > 0001 0000-0010 FFFF   | 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx
  > ```

  跟据上表，解读 UTF-8 编码非常简单。如果一个字节的第一位是`0`，则这个字节单独就是一个字符；如果第一位是`1`，则连续有多少个`1`，就表示当前字符占用多少个字节。前三个字节`EF BB BF`表示这是UTF-8编码。
  下面，还是以汉字`严`为例，演示如何实现 UTF-8 编码。
  
  ```
  严`的 Unicode 是`4E25`（`100111000100101`），根据上表，可以发现`4E25`处在第三行的范围内（`0000 0800 - 0000 FFFF`），因此`严`的 UTF-8 编码需要三个字节，即格式是`1110xxxx 10xxxxxx 10xxxxxx`。然后，从`严`的最后一个二进制位开始，依次从后向前填入格式中的`x`，多出的位补`0`。这样就得到了，`严`的 UTF-8 编码是`11100100 10111000 10100101`，转换成十六进制就是`E4B8A5
  ```

- 大端序和小端序

  Unicode 规范定义，每一个文件的最前面分别加入一个表示编码顺序的字符，这个字符的名字叫做"零宽度非换行空格"（zero width no-break space），用`FEFF`表示。这正好是两个字节，而且`FF`比`FE`大`1`。
  如果一个文本文件的头两个字节是`FE FF`，就表示该文件采用大头方式；如果头两个字节是`FF FE`，就表示该文件采用小头方式。

  ```
  **变量a**
  int a = 0x12345678
  
  **地址的高端与低端**
  0x00000001
  0x00000002
  0x00000003
  0x00000004
  从上倒下，由低到高，地址值小的为低端，地址值大的为高端。
  
  Bit-endian 如此存放(按原来顺序存储)
  0x00000001      -- 12
  0x00000002      -- 34
  0x00000003      -- 56
  0x00000004      -- 78
  
  Little-endian 如此存放(颠倒顺序储存)
  0x00000001      -- 78
  0x00000002      -- 56
  0x00000003      -- 34
  0x00000004      -- 12
  ```
